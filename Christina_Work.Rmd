---
title: "Christina's Work"
author: "Matt Johnson"
date: "4/24/2021"
output: html_document
---

```{r}
library(tidyverse)
library(ggplot2)
library(rgl)
library(MLeval)
```

```{r}
#for embedding interative 3d plot in html
library(knitr)
knit_hooks$set(webgl = hook_webgl)
```


```{r}
sc_pca = read.csv("derived_data/SC.PCA.clean.csv")
fc_pca = read.csv("derived_data/FC.PCA.clean.csv")
mod_fc_data = read.csv("derived_data/model_data_TNPCA_FC.csv")
mod_sc_data = read.csv("derived_data/model_data_TNPCA_SC.csv")
```

```{r}
summary(fc_pca[,87:96])
```

```{r}
table(fc_pca$SSAGA_Mj_Ab_Dep)
```

```{r}
#sample 50 subject from marijuana abuse and non abuse for making plots

mari_abuse<-fc_pca %>%
  drop_na(SSAGA_Mj_Ab_Dep)%>%
  rename(mj_ab = SSAGA_Mj_Ab_Dep)%>%
  mutate(mj_ab = factor(mj_ab))%>%
  group_by(mj_ab)%>%
  sample_n(50)
```

```{r}
#make 2d scatter with pc1 and pc2

ggplot(mari_abuse,aes(x = PC1,y = PC2,color = mj_ab)) + geom_point()+
  labs(color = "Marijuana Abuser?")+
  scale_color_manual(labels = c("non mj abuser","mj abuser"),values = c("#F8766D","#00BFC4"))
```



The plot is not particularly interesting. Could be that MJ abuse doesn't correspond to different brain structures.

Do graph for alcohol abusers

```{r}
summary(mod_fc_data[,61:65])
#number in each class for hard drug, mari usem and alcohol
table(mod_fc_data$hard.drug)
table(mod_fc_data$mari.user)
table(mod_fc_data$Alc)

```



```{r}
ggplot(alc_ab_sample,aes(x = PC1,y = PC2,color = Alc)) + geom_point()+
  labs(color = "Alcohol User?")+
  scale_color_manual(labels = c("non alcohol user","alcohol abuser"),values = c("#F8766D","#00BFC4"))
```

# modeling alcohol on the FC data
```{r}
#wrapper for calculating F1 score during cross validation

f1 <- function(data, lev = NULL, model = NULL) {
        f1_val <- MLmetrics::F1_Score(y_pred = data$pred,
                                      y_true = data$obs,
                                      positive = lev[2])
        c(F1 = f1_val)
}


# wrapper to control the portion of minority class during over sampling

less_rose <- list(name = "Less ROSE",
                func = function (x, y) {
                  library(ROSE)
                  dat <- if (is.data.frame(x)) x else as.data.frame(x)
                  dat$.y <- y
                  dat <- ROSE(.y ~ ., data = dat, p = 0.5)$data
                  list(x = dat[, !grepl(".y", colnames(dat), fixed = TRUE)], 
                       y = dat$.y)
                  },
                first = TRUE)
```

```{r}
library(caret)

set.seed(893)
#create train test split
fc_train <- mod_fc_data %>%
  select(-c(Subject,hard.drug,mari.user))%>%
  mutate(Alc = factor(Alc))%>%
  mutate(Alc = recode(Alc,"0" = "No","1"="Yes"))
train = createDataPartition(y = fc_train$Alc,p = 0.8,list = FALSE)
alc_train = fc_train[train,]
alc_test = fc_train[-train,]
#check if the split is stratified
table(alc_train$Alc)
table(alc_test$Alc)
```

```{r}
#train a random forest first?
#5-fold cv
#random search over parameters mtry, which is the number of predictors given to each tree
#also calculate F1 score for each param, note that the positive class is "yes"
control <- trainControl(method = "cv",
                        number = 5,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        search = 'random')

alc_rf_random <- train(Alc~.,
                       data = alc_train,
                       method = 'rf',
                       metric = 'F1',
                       tuneLength = 15,
                       trControl = control)
print(alc_rf_random)
```

might have two problem at hand: too many parameters and inbalanced class
only keep 20 most important variables?


#use ROSE during re-sampling i.e in each iteration of CV

ROSE(randomly over-sampling examples) creates a sample of synthetic data by enlarging the features space of minority and majority class examples. Operationally, the new examples are drawn from a conditional kernel density estimate of the two classes, as described in Menardi and Torelli (2013).

# lasso

```{r}
ROSE_control <- trainControl(method = "repeatedcv",
                        number = 10,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = "rose")

# relationship between alcohol and brain structure is a lot harder to learn
glmnet_alc_rose_all <- train(Alc ~ .,
                     data = alc_train,
                     method = 'glmnet',
                     metric = 'F1',
                     tuneGrid = expand.grid(alpha = 1,lambda = seq(0.001,0.01,by = 0.0002)),
                     trControl = ROSE_control)

print(glmnet_alc_rose_all)
```

```{r}
confusionMatrix(glmnet_alc_rose_all,mode = "prec_recall",positive = "Yes")
```

```{r}
coef()
```

recall = 0.5 , precision = 0.22

```{r}
#would lowering minority class probability help?
# lower minority class probability from 0.6 to 0.5
less_rose <- list(name = "Less ROSE",
                func = function (x, y) {
                  library(ROSE)
                  dat <- if (is.data.frame(x)) x else as.data.frame(x)
                  dat$.y <- y
                  dat <- ROSE(.y ~ ., data = dat, p = 0.4)$data
                  list(x = dat[, !grepl(".y", colnames(dat), fixed = TRUE)], 
                       y = dat$.y)
                  },
                first = TRUE)

ROSE_control <- trainControl(method = "repeatedcv",
                        number = 10,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = less_rose)

# relationship between alcohol and brain structure is a lot harder to learn
glmnet_alc_rose_all <- train(Alc ~ .,
                     data = alc_train,
                     method = 'glmnet',
                     metric = 'F1',
                     tuneGrid = expand.grid(alpha = 1,lambda = seq(0.001,0.01,by = 0.0002)),
                     trControl = ROSE_control)

print(glmnet_alc_rose_all)
```


```{r}
confusionMatrix(glmnet_alc_rose_all)
```
recall decreased drastically while precision improved somewhat

```{r}
#what if we increased minority class probability
more_rose <- list(name = "Less ROSE",
                func = function (x, y) {
                  library(ROSE)
                  dat <- if (is.data.frame(x)) x else as.data.frame(x)
                  dat$.y <- y
                  dat <- ROSE(.y ~ ., data = dat, p = 0.8)$data
                  list(x = dat[, !grepl(".y", colnames(dat), fixed = TRUE)], 
                       y = dat$.y)
                  },
                first = TRUE)

ROSE_control <- trainControl(method = "repeatedcv",
                        number = 10,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = more_rose)

# relationship between alcohol and brain structure is a lot harder to learn
glmnet_alc_rose_all <- train(Alc ~ .,
                     data = alc_train,
                     method = 'glmnet',
                     metric = 'F1',
                     tuneGrid = expand.grid(alpha = 1,lambda = seq(0.001,0.01,by = 0.0002)),
                     trControl = ROSE_control)

print(glmnet_alc_rose_all)
```

```{r}
confusionMatrix(glmnet_alc_rose_all)
```

recall close to 100 percent while precision maintains around 20 %
It seems that as minority class probability increase, we complete bias the model towards the minority class. The default is not so bad.

30,31,56 seemed most important
```{r}
varImp(glmnet_alc_rose_all)
```


# Random Forest
```{r}
#over sample with the entire data set
#do it inside each CV iteration
ROSE_control <- trainControl(method = "repeatedcv",
                        number = 5,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = "rose")

alc_rf_ROSE <- train(Alc~.,
                       data = alc_train,
                       method = 'rf',
                       metric = 'F1',
                       tuneLength = 5,
                       trControl = ROSE_control)
print(alc_rf_ROSE)
```
not doing better than lasso

```{r}
#see trainning precision and recall for the best model
#compared to validation F1 which is 0.30, seems to be overfitting
rf_pred = predict(alc_rf_ROSE$finalModel,alc_train[,-ncol(alc_train)])
confusionMatrix(rf_pred,alc_train[,ncol(alc_train)],positive = "Yes",mode = "prec_recall")
```

# variable importance and selection with the rose model, maybe that would help with overfitting
```{r}
var_imp_fc_rose <- varImp(alc_rf_ROSE$finalModel) %>%
  tibble::rownames_to_column()%>%
  arrange(desc(Overall))

#very different result compared to not using rose
#extract names of the 20 most important factors for subsequent use
imp_var_fc_rose <-(var_imp_fc_rose %>% head(20))$rowname
```

```{r}
var_imp_fc_rose %>%
  filter(Overall >= mean(var_imp_fc_rose$Overall))
```

```{r}
ROSE_control <- trainControl(method = "repeatedcv",
                        number = 5,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = "rose",
                        search = 'random')

#retrain the model with only "important" variables and rose
alc_rf_ROSE_imp_var <- train(Alc~.,
                       data = alc_train[,c(imp_var_fc_rose,"Alc")],
                       method = 'rf',
                       metric = 'F1',
                       tuneLength = 15,
                       trControl = ROSE_control)
print(alc_rf_ROSE_imp_var)
```
confusian matrix for all cv iterations
```{r}
confusionMatrix(alc_rf_ROSE_imp_var)
```

# trainning accuracy with only 20 important variables
```{r}
train_pred <- predict(alc_rf_ROSE_imp_var$finalModel,alc_train[,imp_var_fc_rose])
confusionMatrix(train_pred,alc_train$Alc,mode = "prec_recall",positive = "Yes")
```


```{r}
test_pred <- predict(alc_rf_ROSE_imp_var$finalModel,alc_test[,imp_var_fc_rose])
confusionMatrix(test_pred,alc_test$Alc,mode = "prec_recall",positive = "Yes")
ROSE::roc.curve(test_pred,alc_test$Alc)
```

The test recall is not that bad, but at the cost of low Precision




# Modeling alcohol use on the SC data
```{r}
set.seed(893)
#create train test split
sc_train <- mod_sc_data %>%
  select(-c(Subject,hard.drug,mari.user))%>%
  mutate(Alc = factor(Alc))%>%
  mutate(Alc = recode(Alc,"0" = "No","1"="Yes"))
train = createDataPartition(y = sc_train$Alc,p = 0.8,list = FALSE)
alc_train_sc = sc_train[train,]
alc_test_sc = sc_train[-train,]
#check if the split is stratified
table(alc_train_sc$Alc)
table(alc_test_sc$Alc)
```


```{r}
levels(drug_train$hard.drug)
```


```{r}
#10-fold cv
#random search over parameters mtry, which is the number of predictors given to each tree
#no oversampling
control <- trainControl(method = "cv",
                        number = 5,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        search = 'random')

sc_alc_rf_random<- train(Alc~.,
                       data = alc_train_sc,
                       method = 'rf',
                       metric = 'F1',
                       tuneLength = 15,
                       trControl = control)
print(sc_alc_rf_random)
```
It seems that ROC are not improving regradless of what we do.


# try again with ROSE

```{r}
sc_alc_rf_random<- train(Alc~.,
                       data = alc_train_sc,
                       method = 'rf',
                       metric = 'F1',
                       tuneLength = 15,
                       trControl = ROSE_control)
print(sc_alc_rf_random)
```

# it seems that learning to identify who is alcohol abusers are even more difficult with the SC data set
```{r}
confusionMatrix(sc_alc_rf_random)
```

Speculations:

1. Bundling varying levels of alcol use/dependency together added a lot of noise
2. Random forest is a not a good algorithm for this problem

# try modeling with hard drugs

let's only work with FC data 
```{r}

mod_fc_drug<-mod_fc_data%>%
  select(-c(Subject,Alc,mari.user)) %>%
  mutate(hard.drug = factor(hard.drug))%>%
  mutate(hard.drug = recode(hard.drug,"0" = "No","1" = "Yes"))

train = createDataPartition(y = mod_fc_drug$hard.drug,p = 0.8,list = FALSE)
drug_train = mod_fc_drug[train,]
drug_test = mod_fc_drug[-train,]

table(drug_train$hard.drug)
table(drug_test$hard.drug)
```

```{r}
control <- trainControl(method = "repeatedcv",
                        number = 5,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        search = 'random')

rf_drug_all <- train(hard.drug ~ .,
                     data = drug_train,
                     metric = 'F1',
                     method = 'rf',
                     tuneLength = 15,
                     trControl = control)
```

```{r}
print(rf_drug_all)
```

actually let's try glmnet first
```{r}

ROSE_control <- trainControl(method = "repeatedcv",
                        number = 10,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = "rose",
                        search = 'random')



glmnet_drug_rose_all <- train(hard.drug ~ .,
                     data = drug_train,
                     method = 'glmnet',
                     metric = 'F1',
                     tuneGrid = expand.grid(alpha = 1,lambda = seq(0.001,0.01,by = 0.0001)),
                     trControl = ROSE_control)

print(glmnet_drug_rose_all)
```

Best lambda is 0.0044, corresponding to a F1 score of 0.1066

```{r}
confusionMatrix(glmnet_drug_rose_all)
```

```{r}
coef(glmnet_drug_rose_all$finalModel,s = 0.0044)
```


most important features are PC19, PC14, PC54

# Random forest is actually do
```{r}
ROSE_control <- trainControl(method = "repeatedcv",
                        number = 5,
                        repeats = 3,
                        summaryFunction = f1,
                        classProbs = TRUE,
                        sampling = "rose",
                        search = 'random')

#wrapper for calculating F1 score during cross validation 

rf_drug_rose_all <- train(hard.drug ~ .,
                     data = drug_train,
                     method = 'rf',
                     metric = 'F1',
                     tuneLength = 15,
                     trControl = ROSE_control)
print(rf_drug_rose_all)
```

```{r}
varImp(rf_drug_rose_all$finalModel)%>%
  rownames_to_column()%>%
  arrange(desc(Overall)) %>%
  head(20)
```

```{r}
pred <- predict(rf_drug_rose_all$finalModel,drug_test[,-ncol(drug_test)])
MLmetrics::F1_Score(drug_test[,ncol(drug_test)],pred,positive = "Yes")
MLmetrics::ConfusionMatrix(pred,drug_test[,ncol(drug_test)])
ROSE::roc.curve(drug_test[,ncol(drug_test)],pred)
```


```{r}
evalm(rf_drug_rose_all)
```

```{r}
confusionMatrix(rf_drug_rose_all)
```



